{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Advanced Multi-Agent System Evaluation Demo\n",
    "\n",
    "This notebook demonstrates a complete MAS (Multi-Agent System) with:\n",
    "- **Parallel Researchers** - Two researchers working simultaneously\n",
    "- **Sequential Writer** - Aggregating research into a document\n",
    "- **Critic Loop** - Iterative refinement with quality feedback\n",
    "\n",
    "All agents use Google ADK with Gemini 2.5 Flash, and the full `mas_eval` evaluation framework runs on captured traces.\n",
    "\n",
    "### Architecture\n",
    "```\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ Researcher A â”‚     â”‚ Researcher B â”‚\n",
    "    â”‚  (parallel)  â”‚     â”‚  (parallel)  â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚                     â”‚\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                      â–¼\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚    Writer     â”‚\n",
    "              â”‚ (aggregator)  â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                      â”‚\n",
    "                      â–¼\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚    Critic     â”‚â—„â”€â”€â”€â”€â”€â”\n",
    "              â”‚   (review)    â”‚      â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "                      â”‚              â”‚\n",
    "                      â–¼              â”‚\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "              â”‚  Revise if    â”‚â”€â”€â”€â”€â”€â”€â”˜\n",
    "              â”‚   needed      â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Installation\n",
    "\n",
    "First, let's install all required dependencies including Google ADK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q google-adk google-genai networkx numpy sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”‘ Step 2: API Key Configuration\n",
    "\n",
    "Set your Google API key. In Colab, you can use Secrets or set it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Option 1: Use Colab Secrets (recommended)\n",
    "try:\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
    "    print(\"âœ… API key loaded from Colab Secrets\")\n",
    "except:\n",
    "    # Option 2: Set directly (not recommended for sharing)\n",
    "    # os.environ['GOOGLE_API_KEY'] = 'your-api-key-here'\n",
    "    print(\"âš ï¸ Please set GOOGLE_API_KEY in Colab Secrets or uncomment the line above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Step 3: Upload mas_eval Framework\n",
    "\n",
    "Upload your `mas_eval` folder to Colab, or clone it from your repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload mas_eval folder manually using the file browser on the left\n",
    "# Then run:\n",
    "import sys\n",
    "sys.path.insert(0, '/content')\n",
    "\n",
    "# Option 2: Clone from GitHub (if available)\n",
    "# !git clone https://github.com/your-repo/mas_eval.git\n",
    "\n",
    "# Verify mas_eval is importable\n",
    "try:\n",
    "    from mas_eval.adapters.adk_adapter import ADKTracingCallback\n",
    "    print(\"âœ… mas_eval framework loaded successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Failed to import mas_eval: {e}\")\n",
    "    print(\"Please upload the mas_eval folder to /content/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Step 4: Import All Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import uuid\n",
    "\n",
    "# Google ADK\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "# mas_eval components\n",
    "from mas_eval.adapters.adk_adapter import ADKTracingCallback\n",
    "from mas_eval.graph.crg_builder import CRGModule\n",
    "from mas_eval.graph.agent_graph import AgentGraphBuilder, AgentGraphEvaluator\n",
    "from mas_eval.graph.visualizer import GraphVisualizer\n",
    "from mas_eval.mast.classifier import MASTClassifier, ClassifierMode\n",
    "from mas_eval.metrics.gemmas import GEMMASMetrics\n",
    "from mas_eval.metrics.thought_relevance import ThoughtRelevanceMetric\n",
    "from mas_eval.suggestions.advisor import MASAdvisor\n",
    "from mas_eval.evaluator import MASEvaluator\n",
    "from mas_eval.core.types import Span, TraceData\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– Step 5: Define Agent Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCHER_A_INSTRUCTION = \"\"\"You are Researcher A, an expert in technical analysis and data gathering.\n",
    "\n",
    "Your role:\n",
    "- Research the TECHNICAL aspects of the given topic\n",
    "- Focus on: implementation details, technologies, architectures, technical challenges\n",
    "- Provide specific facts, statistics, and technical specifications\n",
    "- Be thorough but concise\n",
    "\n",
    "When given a topic, provide a comprehensive technical research summary.\n",
    "Format your findings clearly with bullet points or numbered lists.\n",
    "Always start with \"TECHNICAL RESEARCH FINDINGS:\" as your header.\n",
    "\"\"\"\n",
    "\n",
    "RESEARCHER_B_INSTRUCTION = \"\"\"You are Researcher B, an expert in market analysis and trends.\n",
    "\n",
    "Your role:\n",
    "- Research the MARKET and BUSINESS aspects of the given topic  \n",
    "- Focus on: market trends, business applications, industry adoption, economic impact\n",
    "- Provide specific examples, case studies, and market data\n",
    "- Be thorough but concise\n",
    "\n",
    "When given a topic, provide a comprehensive market/business research summary.\n",
    "Format your findings clearly with bullet points or numbered lists.\n",
    "Always start with \"MARKET RESEARCH FINDINGS:\" as your header.\n",
    "\"\"\"\n",
    "\n",
    "WRITER_INSTRUCTION = \"\"\"You are the Writer/Aggregator agent.\n",
    "\n",
    "Your role:\n",
    "- Combine and synthesize research from multiple sources into a coherent document\n",
    "- Create a well-structured, comprehensive summary\n",
    "- Ensure all key points from the research are included\n",
    "- Add logical flow and transitions between sections\n",
    "- Make the content accessible and professional\n",
    "\n",
    "When given research inputs, create a unified document with:\n",
    "1. Executive Summary\n",
    "2. Technical Overview (from Researcher A)\n",
    "3. Market Analysis (from Researcher B)  \n",
    "4. Key Insights and Conclusions\n",
    "\n",
    "Start your output with \"COMPREHENSIVE REPORT:\" as your header.\n",
    "\"\"\"\n",
    "\n",
    "CRITIC_INSTRUCTION = \"\"\"You are the Critic agent, responsible for quality assurance.\n",
    "\n",
    "Your role:\n",
    "- Review the written document for completeness and quality\n",
    "- Check for: accuracy, clarity, coherence, missing information\n",
    "- Provide specific, actionable feedback\n",
    "- Rate the document's quality\n",
    "\n",
    "Provide your critique in this format:\n",
    "QUALITY ASSESSMENT:\n",
    "- Overall Score: [1-10]\n",
    "- Completeness: [1-10]\n",
    "- Clarity: [1-10]\n",
    "- Coherence: [1-10]\n",
    "\n",
    "STRENGTHS:\n",
    "- [List strengths]\n",
    "\n",
    "ISSUES TO ADDRESS:\n",
    "- [List specific issues with suggestions]\n",
    "\n",
    "VERDICT: [APPROVED / NEEDS_REVISION]\n",
    "\n",
    "If NEEDS_REVISION, explain exactly what needs to be fixed.\n",
    "Only approve if the document truly meets high quality standards.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… Agent instructions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Step 6: Create Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agents():\n",
    "    \"\"\"Create all ADK agents for the MAS.\"\"\"\n",
    "    model = \"gemini-2.5-flash\"\n",
    "    \n",
    "    researcher_a = Agent(\n",
    "        name=\"ResearcherA\",\n",
    "        model=model,\n",
    "        instruction=RESEARCHER_A_INSTRUCTION,\n",
    "    )\n",
    "    \n",
    "    researcher_b = Agent(\n",
    "        name=\"ResearcherB\",\n",
    "        model=model,\n",
    "        instruction=RESEARCHER_B_INSTRUCTION,\n",
    "    )\n",
    "    \n",
    "    writer = Agent(\n",
    "        name=\"Writer\",\n",
    "        model=model,\n",
    "        instruction=WRITER_INSTRUCTION,\n",
    "    )\n",
    "    \n",
    "    critic = Agent(\n",
    "        name=\"Critic\",\n",
    "        model=model,\n",
    "        instruction=CRITIC_INSTRUCTION,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"researcher_a\": researcher_a,\n",
    "        \"researcher_b\": researcher_b,\n",
    "        \"writer\": writer,\n",
    "        \"critic\": critic\n",
    "    }\n",
    "\n",
    "agents = create_agents()\n",
    "print(f\"âœ… Created {len(agents)} agents: {list(agents.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Step 7: Agent Execution Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agent(\n",
    "    agent: Agent,\n",
    "    message: str,\n",
    "    callback: ADKTracingCallback,\n",
    "    session_id: str = None,\n",
    "    user_id: str = \"user\"\n",
    ") -> Tuple[str, List[Span]]:\n",
    "    \"\"\"Run a single agent and capture spans.\"\"\"\n",
    "    runner = InMemoryRunner(agent=agent, app_name=f\"mas-{agent.name}\")\n",
    "    session_id = session_id or str(uuid.uuid4())\n",
    "    \n",
    "    session = await runner.session_service.create_session(\n",
    "        app_name=f\"mas-{agent.name}\",\n",
    "        user_id=user_id\n",
    "    )\n",
    "    \n",
    "    final_response = \"\"\n",
    "    async for event in runner.run_async(\n",
    "        user_id=user_id,\n",
    "        session_id=session.id,\n",
    "        new_message=types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part(text=message)]\n",
    "        )\n",
    "    ):\n",
    "        callback.on_event(event)\n",
    "        \n",
    "        if hasattr(event, 'content') and event.content:\n",
    "            if hasattr(event.content, 'parts'):\n",
    "                for part in event.content.parts:\n",
    "                    if hasattr(part, 'text') and part.text:\n",
    "                        final_response = part.text\n",
    "    \n",
    "    return final_response, callback.get_spans()\n",
    "\n",
    "\n",
    "async def run_parallel_researchers(\n",
    "    researcher_a: Agent,\n",
    "    researcher_b: Agent,\n",
    "    topic: str,\n",
    "    callback: ADKTracingCallback\n",
    ") -> Tuple[str, str]:\n",
    "    \"\"\"Run two researchers in parallel.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ”¬ PHASE 1: PARALLEL RESEARCH\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ðŸ“‹ Topic: {topic[:100]}...\")\n",
    "    print(\"âš¡ Running Researcher A and Researcher B in parallel...\")\n",
    "    \n",
    "    callback_a = ADKTracingCallback(service_name=\"researcher-a\", verbose=False)\n",
    "    callback_b = ADKTracingCallback(service_name=\"researcher-b\", verbose=False)\n",
    "    \n",
    "    task_a = run_agent(researcher_a, topic, callback_a)\n",
    "    task_b = run_agent(researcher_b, topic, callback_b)\n",
    "    \n",
    "    results = await asyncio.gather(task_a, task_b)\n",
    "    \n",
    "    research_a, spans_a = results[0]\n",
    "    research_b, spans_b = results[1]\n",
    "    \n",
    "    # Merge spans into main callback\n",
    "    for span in spans_a:\n",
    "        callback._spans.append(span)\n",
    "        callback._span_id_set.add(span.span_id)\n",
    "    for span in spans_b:\n",
    "        callback._spans.append(span)\n",
    "        callback._span_id_set.add(span.span_id)\n",
    "    \n",
    "    print(f\"âœ… Researcher A completed: {len(research_a)} chars\")\n",
    "    print(f\"âœ… Researcher B completed: {len(research_b)} chars\")\n",
    "    \n",
    "    return research_a, research_b\n",
    "\n",
    "\n",
    "async def run_writer(\n",
    "    writer: Agent,\n",
    "    research_a: str,\n",
    "    research_b: str,\n",
    "    callback: ADKTracingCallback\n",
    ") -> str:\n",
    "    \"\"\"Run writer to aggregate research.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœï¸  PHASE 2: AGGREGATION & WRITING\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"ðŸ“ Combining research from both researchers...\")\n",
    "    \n",
    "    writer_input = f\"\"\"Please combine and synthesize the following research into a comprehensive document:\n",
    "\n",
    "--- RESEARCHER A (Technical Analysis) ---\n",
    "{research_a}\n",
    "\n",
    "--- RESEARCHER B (Market Analysis) ---\n",
    "{research_b}\n",
    "\n",
    "Create a unified, well-structured document that incorporates insights from both research sources.\n",
    "\"\"\"\n",
    "    \n",
    "    writer_callback = ADKTracingCallback(service_name=\"writer\", verbose=False)\n",
    "    document, spans = await run_agent(writer, writer_input, writer_callback)\n",
    "    \n",
    "    for span in spans:\n",
    "        callback._spans.append(span)\n",
    "        callback._span_id_set.add(span.span_id)\n",
    "    \n",
    "    print(f\"âœ… Writer completed: {len(document)} chars\")\n",
    "    \n",
    "    return document\n",
    "\n",
    "\n",
    "async def run_critic_loop(\n",
    "    writer: Agent,\n",
    "    critic: Agent,\n",
    "    initial_document: str,\n",
    "    callback: ADKTracingCallback,\n",
    "    max_iterations: int = 2\n",
    ") -> Tuple[str, int]:\n",
    "    \"\"\"Run critic loop for document refinement.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ”„ PHASE 3: CRITIC REVIEW LOOP\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    current_document = initial_document\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        print(f\"\\n--- Critic Review Iteration {iteration}/{max_iterations} ---\")\n",
    "        \n",
    "        critic_callback = ADKTracingCallback(service_name=f\"critic-{iteration}\", verbose=False)\n",
    "        critique, spans = await run_agent(\n",
    "            critic,\n",
    "            f\"Please review this document:\\n\\n{current_document}\",\n",
    "            critic_callback\n",
    "        )\n",
    "        \n",
    "        for span in spans:\n",
    "            callback._spans.append(span)\n",
    "            callback._span_id_set.add(span.span_id)\n",
    "        \n",
    "        print(f\"ðŸ“‹ Critic feedback received ({len(critique)} chars)\")\n",
    "        \n",
    "        if \"APPROVED\" in critique.upper() and \"NEEDS_REVISION\" not in critique.upper():\n",
    "            print(\"âœ… Document APPROVED by Critic!\")\n",
    "            break\n",
    "        \n",
    "        print(\"ðŸ”„ Document needs revision, running writer again...\")\n",
    "        \n",
    "        revision_prompt = f\"\"\"Please revise this document based on the critic's feedback:\n",
    "\n",
    "CURRENT DOCUMENT:\n",
    "{current_document}\n",
    "\n",
    "CRITIC'S FEEDBACK:\n",
    "{critique}\n",
    "\n",
    "Create an improved version addressing all the issues mentioned.\n",
    "\"\"\"\n",
    "        \n",
    "        revision_callback = ADKTracingCallback(service_name=f\"revision-{iteration}\", verbose=False)\n",
    "        current_document, spans = await run_agent(writer, revision_prompt, revision_callback)\n",
    "        \n",
    "        for span in spans:\n",
    "            callback._spans.append(span)\n",
    "            callback._span_id_set.add(span.span_id)\n",
    "        \n",
    "        print(f\"ðŸ“ Revision completed ({len(current_document)} chars)\")\n",
    "    \n",
    "    if iteration >= max_iterations:\n",
    "        print(f\"âš ï¸  Reached max iterations ({max_iterations})\")\n",
    "    \n",
    "    return current_document, iteration\n",
    "\n",
    "print(\"âœ… Execution helpers defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Step 8: Run the MAS Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_mas_pipeline(topic: str) -> Tuple[str, ADKTracingCallback]:\n",
    "    \"\"\"Run the complete MAS pipeline.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸš€ ADVANCED MULTI-AGENT SYSTEM DEMO\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"ðŸŽ¯ Topic: {topic[:100]}...\")\n",
    "    print(f\"â° Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    agents = create_agents()\n",
    "    \n",
    "    master_callback = ADKTracingCallback(\n",
    "        service_name=\"advanced-mas\",\n",
    "        verbose=True,\n",
    "        max_spans=10000\n",
    "    )\n",
    "    \n",
    "    # Phase 1: Parallel Research\n",
    "    research_a, research_b = await run_parallel_researchers(\n",
    "        agents[\"researcher_a\"],\n",
    "        agents[\"researcher_b\"],\n",
    "        topic,\n",
    "        master_callback\n",
    "    )\n",
    "    \n",
    "    # Phase 2: Sequential Writing\n",
    "    initial_document = await run_writer(\n",
    "        agents[\"writer\"],\n",
    "        research_a,\n",
    "        research_b,\n",
    "        master_callback\n",
    "    )\n",
    "    \n",
    "    # Phase 3: Critic Loop\n",
    "    final_document, iterations = await run_critic_loop(\n",
    "        agents[\"writer\"],\n",
    "        agents[\"critic\"],\n",
    "        initial_document,\n",
    "        master_callback,\n",
    "        max_iterations=2\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… MAS PIPELINE COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"ðŸ“Š Total spans captured: {len(master_callback.get_spans())}\")\n",
    "    print(f\"ðŸ”„ Critic iterations: {iterations}\")\n",
    "    \n",
    "    return final_document, master_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the research topic\n",
    "topic = \"\"\"\n",
    "Research the topic: \"The Impact of Large Language Models on Software Development\"\n",
    "\n",
    "Cover both technical aspects (how LLMs work, integration methods, tooling) \n",
    "and market/business aspects (adoption rates, industry trends, economic impact).\n",
    "\"\"\"\n",
    "\n",
    "# Run the MAS pipeline\n",
    "final_document, callback = await run_mas_pipeline(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“„ Step 9: View Final Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“„ FINAL DOCUMENT\")\n",
    "print(\"=\"*70)\n",
    "display(Markdown(final_document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 10: Run Full Evaluation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_evaluation(\n",
    "    callback: ADKTracingCallback,\n",
    "    task_description: str = \"Research and write a comprehensive document\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run the complete evaluation framework on captured traces.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“Š RUNNING FULL EVALUATION FRAMEWORK\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = {}\n",
    "    spans = callback.get_spans()\n",
    "    \n",
    "    if not spans:\n",
    "        print(\"âš ï¸  No spans captured! Cannot run evaluation.\")\n",
    "        return {\"error\": \"No spans captured\"}\n",
    "    \n",
    "    print(f\"ðŸ“‹ Evaluating {len(spans)} spans from {len(set(s.agent_name for s in spans))} agents\")\n",
    "    \n",
    "    # 1. CRG Construction\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"1ï¸âƒ£  CAUSAL REASONING GRAPH (CRG)\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    crg = CRGModule()\n",
    "    graph = crg.build(spans)\n",
    "    crg_stats = crg.get_statistics()\n",
    "    print(f\"   Nodes: {crg_stats.get('num_nodes', 0)}\")\n",
    "    print(f\"   Edges: {crg_stats.get('num_edges', 0)}\")\n",
    "    print(f\"   Agents: {crg_stats.get('agents', [])}\")\n",
    "    results[\"crg\"] = crg_stats\n",
    "    \n",
    "    # 2. Agent Interaction Graph\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"2ï¸âƒ£  AGENT INTERACTION GRAPH\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    agent_graph_builder = AgentGraphBuilder()\n",
    "    agent_graph = agent_graph_builder.build(spans)\n",
    "    agent_evaluator = AgentGraphEvaluator()\n",
    "    agent_metrics = agent_evaluator.evaluate(agent_graph, spans)\n",
    "    \n",
    "    print(f\"   Agent Count: {agent_metrics.get('agent_count', 0)}\")\n",
    "    print(f\"   Collaboration Score: {agent_metrics.get('overall_score', 0):.2%}\")\n",
    "    results[\"agent_graph\"] = agent_metrics\n",
    "    \n",
    "    # 3. GEMMAS Metrics\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"3ï¸âƒ£  GEMMAS METRICS (IDS & UPR)\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    gemmas = GEMMASMetrics()\n",
    "    gemmas_metrics = gemmas.compute(graph, spans)\n",
    "    \n",
    "    print(f\"   IDS (Information Diversity): {gemmas_metrics.get('IDS', 0):.4f}\")\n",
    "    print(f\"   UPR (Unnecessary Path Ratio): {gemmas_metrics.get('UPR', 0):.4f}\")\n",
    "    results[\"gemmas\"] = gemmas_metrics\n",
    "    \n",
    "    # 4. Thought Relevance\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"4ï¸âƒ£  THOUGHT RELEVANCE SCORING\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    try:\n",
    "        relevance_metric = ThoughtRelevanceMetric()\n",
    "        relevance_scores = relevance_metric.compute(spans, task_description)\n",
    "        print(f\"   Average Relevance: {relevance_scores.get('average_relevance', 0):.4f}\")\n",
    "        results[\"thought_relevance\"] = relevance_scores\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Failed: {e}\")\n",
    "        results[\"thought_relevance\"] = {\"error\": str(e)}\n",
    "    \n",
    "    # 5. MAST Classification\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"5ï¸âƒ£  MAST FAILURE MODE CLASSIFICATION\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    try:\n",
    "        mast = MASTClassifier(\n",
    "            mode=ClassifierMode.FEW_SHOT,\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            verbose=True\n",
    "        )\n",
    "        failure_modes = mast.classify(spans, task_description=task_description)\n",
    "        \n",
    "        if failure_modes:\n",
    "            print(f\"\\n   ðŸš¨ Detected {len(failure_modes)} potential failure modes:\")\n",
    "            for fm in failure_modes:\n",
    "                print(f\"   [{fm.code}] {fm.name} - {fm.get_probability_percentage()}\")\n",
    "        else:\n",
    "            print(\"   âœ… No significant failure modes detected!\")\n",
    "        \n",
    "        results[\"mast\"] = {\n",
    "            \"failure_count\": len(failure_modes),\n",
    "            \"failures\": [{\n",
    "                \"code\": fm.code,\n",
    "                \"name\": fm.name,\n",
    "                \"category\": fm.category,\n",
    "                \"probability\": fm.get_probability()\n",
    "            } for fm in failure_modes]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Failed: {e}\")\n",
    "        results[\"mast\"] = {\"error\": str(e), \"failure_count\": 0}\n",
    "    \n",
    "    # 6. MAS Improvement Suggestions\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"6ï¸âƒ£  MAS IMPROVEMENT SUGGESTIONS\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    try:\n",
    "        advisor = MASAdvisor(model=\"gemini-2.5-flash\")\n",
    "        suggestions = advisor.generate_suggestions_from_data(\n",
    "            spans=spans,\n",
    "            failures=[],\n",
    "            metrics=results.get(\"gemmas\", {}),\n",
    "            graph_stats=results.get(\"crg\", {}),\n",
    "            task_description=task_description\n",
    "        )\n",
    "        \n",
    "        if suggestions:\n",
    "            print(\"\\n   ðŸ“ Improvement Suggestions:\")\n",
    "            for i, s in enumerate(suggestions[:3], 1):\n",
    "                title = s.title if hasattr(s, 'title') else s.get('title', 'Suggestion')\n",
    "                print(f\"   {i}. {title}\")\n",
    "        # Convert Suggestion objects to dicts for JSON serialization\n",
    "        results[\"suggestions\"] = [s.to_dict() if hasattr(s, 'to_dict') else s for s in suggestions[:5]] if suggestions else []\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Failed: {e}\")\n",
    "        results[\"suggestions\"] = {\"error\": str(e)}\n",
    "    \n",
    "    # Calculate overall score\n",
    "    ids = results.get(\"gemmas\", {}).get(\"IDS\", 0.5)\n",
    "    upr = results.get(\"gemmas\", {}).get(\"UPR\", 0.5)\n",
    "    collab = results.get(\"agent_graph\", {}).get(\"overall_score\", 0.5)\n",
    "    failure_count = results.get(\"mast\", {}).get(\"failure_count\", 0)\n",
    "    \n",
    "    quality_score = (\n",
    "        ids * 0.25 +\n",
    "        (1 - upr) * 0.25 +\n",
    "        collab * 0.25 +\n",
    "        max(0, 1 - failure_count * 0.1) * 0.25\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“Š EVALUATION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   â­ OVERALL QUALITY SCORE: {quality_score:.2%}\")\n",
    "    \n",
    "    results[\"overall_score\"] = quality_score\n",
    "    results[\"timestamp\"] = datetime.now().isoformat()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the evaluation\n",
    "task_desc = \"Research and write a comprehensive document about LLMs in software development\"\n",
    "results = run_full_evaluation(callback, task_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 11: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def create_results_dashboard(results: Dict[str, Any]) -> str:\n",
    "    \"\"\"Create an HTML dashboard for results.\"\"\"\n",
    "    overall = results.get('overall_score', 0)\n",
    "    ids = results.get('gemmas', {}).get('IDS', 0)\n",
    "    upr = results.get('gemmas', {}).get('UPR', 0)\n",
    "    collab = results.get('agent_graph', {}).get('overall_score', 0)\n",
    "    failures = results.get('mast', {}).get('failure_count', 0)\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"font-family: system-ui; background: #1e293b; color: #f1f5f9; padding: 20px; border-radius: 16px;\">\n",
    "        <h2 style=\"color: #818cf8; margin-bottom: 20px;\">ðŸ“Š MAS Evaluation Dashboard</h2>\n",
    "        \n",
    "        <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px;\">\n",
    "            <div style=\"background: #334155; padding: 15px; border-radius: 12px; text-align: center;\">\n",
    "                <div style=\"font-size: 2em; color: #22c55e;\">{overall:.0%}</div>\n",
    "                <div style=\"color: #94a3b8;\">Overall Score</div>\n",
    "            </div>\n",
    "            <div style=\"background: #334155; padding: 15px; border-radius: 12px; text-align: center;\">\n",
    "                <div style=\"font-size: 2em; color: #6366f1;\">{ids:.2%}</div>\n",
    "                <div style=\"color: #94a3b8;\">Info Diversity</div>\n",
    "            </div>\n",
    "            <div style=\"background: #334155; padding: 15px; border-radius: 12px; text-align: center;\">\n",
    "                <div style=\"font-size: 2em; color: #f59e0b;\">{upr:.2%}</div>\n",
    "                <div style=\"color: #94a3b8;\">Path Ratio</div>\n",
    "            </div>\n",
    "            <div style=\"background: #334155; padding: 15px; border-radius: 12px; text-align: center;\">\n",
    "                <div style=\"font-size: 2em; color: #a855f7;\">{collab:.2%}</div>\n",
    "                <div style=\"color: #94a3b8;\">Collaboration</div>\n",
    "            </div>\n",
    "            <div style=\"background: #334155; padding: 15px; border-radius: 12px; text-align: center;\">\n",
    "                <div style=\"font-size: 2em; color: {'#ef4444' if failures > 0 else '#22c55e'};\">{failures}</div>\n",
    "                <div style=\"color: #94a3b8;\">Failures Found</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return html\n",
    "\n",
    "display(HTML(create_results_dashboard(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Step 12: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results to JSON\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = f\"evaluation_report_{timestamp}.json\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"âœ… Results saved to: {output_path}\")\n",
    "\n",
    "# Download the file in Colab\n",
    "from google.colab import files\n",
    "files.download(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ‰ Demo Complete!\n",
    "\n",
    "You've successfully run:\n",
    "1. âœ… Parallel research with 2 agents\n",
    "2. âœ… Sequential document writing\n",
    "3. âœ… Iterative critic review loop\n",
    "4. âœ… Full MAS evaluation with MAST classification\n",
    "5. âœ… Quality metrics and improvement suggestions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
