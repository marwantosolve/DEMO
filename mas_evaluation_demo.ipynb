{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAS Evaluation Framework Demo\n",
    "\n",
    "This notebook demonstrates the OTel Capture and Agentic Analytics Converter with a Google ADK Multi-Agent System.\n",
    "\n",
    "**Architecture:**\n",
    "- 2 Researchers (parallel) ‚Üí Writer (sequential) ‚Üí Critic (refinement loop)\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   Researcher 1  ‚îÇ   ‚îÇ   Researcher 2  ‚îÇ\n",
    "‚îÇ   (Technical)   ‚îÇ   ‚îÇ   (Business)    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ                     ‚îÇ\n",
    "         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                    ‚ñº\n",
    "          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "          ‚îÇ     Writer      ‚îÇ\n",
    "          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                   ‚îÇ\n",
    "                   ‚ñº\n",
    "          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "          ‚îÇ     Critic      ‚îÇ‚óÑ‚îÄ‚îÄ‚îê\n",
    "          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "                   ‚îÇ            ‚îÇ (refinement loop)\n",
    "                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q google-genai opentelemetry-api opentelemetry-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Option 1: Colab secrets\n",
    "try:\n",
    "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Option 2: Manual input (uncomment if needed)\n",
    "# os.environ['GOOGLE_API_KEY'] = 'your-api-key-here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the OTel Capture & Converter Modules\n",
    "\n",
    "Upload `otel_capture.py` and `agentic_analytics_converter.py` to Colab first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the modules (run this cell and upload the files)\n",
    "from google.colab import files\n",
    "print(\"Upload otel_capture.py and agentic_analytics_converter.py:\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "from otel_capture import OTelCapture, trace_agent\n",
    "from agentic_analytics_converter import AgenticAnalyticsConverter, convert_otel_to_analytics\n",
    "\n",
    "print(\"‚úÖ Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize OTel Capture (BEFORE Creating Agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tracing - MUST be done before any agent calls\n",
    "capture = OTelCapture(\n",
    "    output_file=\"mas_traces.json\",\n",
    "    service_name=\"mas-research-demo\"\n",
    ")\n",
    "capture.start()\n",
    "\n",
    "# Get a tracer for manual spans\n",
    "tracer = capture.get_tracer(\"research-mas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Google ADK Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from opentelemetry import trace\n",
    "import concurrent.futures\n",
    "\n",
    "# Initialize the GenAI client\n",
    "client = genai.Client(api_key=os.environ.get('GOOGLE_API_KEY'))\n",
    "MODEL = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "# Agent definitions with system prompts\n",
    "AGENTS = {\n",
    "    \"technical_researcher\": {\n",
    "        \"role\": \"Technical Research Specialist\",\n",
    "        \"goal\": \"Find technical details, implementation approaches, and code examples\",\n",
    "        \"system_prompt\": \"\"\"You are a Technical Research Specialist. \n",
    "Your role is to find technical details, implementation approaches, and code examples.\n",
    "Be concise but thorough. Focus on technical accuracy.\"\"\"\n",
    "    },\n",
    "    \"business_researcher\": {\n",
    "        \"role\": \"Business Research Analyst\",\n",
    "        \"goal\": \"Find market trends, use cases, and business value\",\n",
    "        \"system_prompt\": \"\"\"You are a Business Research Analyst.\n",
    "Your role is to find market trends, use cases, and business value.\n",
    "Focus on practical applications and real-world impact.\"\"\"\n",
    "    },\n",
    "    \"writer\": {\n",
    "        \"role\": \"Technical Writer\",\n",
    "        \"goal\": \"Synthesize research into a coherent, well-structured document\",\n",
    "        \"system_prompt\": \"\"\"You are a Technical Writer.\n",
    "Combine the research from multiple sources into a coherent, well-structured document.\n",
    "Make it engaging and informative.\"\"\"\n",
    "    },\n",
    "    \"critic\": {\n",
    "        \"role\": \"Quality Critic\",\n",
    "        \"goal\": \"Review and suggest improvements to the draft\",\n",
    "        \"system_prompt\": \"\"\"You are a Quality Critic.\n",
    "Review the document and provide specific, actionable feedback.\n",
    "If the document is good enough, respond with 'APPROVED'.\n",
    "Otherwise, list the improvements needed.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Agent definitions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_agent(agent_name: str, task: str, context: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Call an agent with OTel tracing.\n",
    "    \"\"\"\n",
    "    agent = AGENTS[agent_name]\n",
    "    tracer = trace.get_tracer(\"research-mas\")\n",
    "    \n",
    "    with tracer.start_as_current_span(\n",
    "        f\"{agent_name}.execute\",\n",
    "        attributes={\n",
    "            \"traceloop.entity.name\": agent_name,\n",
    "            \"crewai.agent.role\": agent[\"role\"],\n",
    "            \"crewai.agent.goal\": agent[\"goal\"],\n",
    "            \"traceloop.entity.input\": task[:500],  # Truncate for span\n",
    "        }\n",
    "    ) as span:\n",
    "        try:\n",
    "            # Build the prompt\n",
    "            prompt = f\"{agent['system_prompt']}\\n\\nTask: {task}\"\n",
    "            if context:\n",
    "                prompt += f\"\\n\\nContext:\\n{context}\"\n",
    "            \n",
    "            # Call the Gemini API with nested LLM span\n",
    "            with tracer.start_as_current_span(\n",
    "                \"llm.generate\",\n",
    "                attributes={\n",
    "                    \"llm.model\": MODEL,\n",
    "                    \"llm.request_type\": \"chat\",\n",
    "                    \"gen_ai.request.model\": MODEL,\n",
    "                }\n",
    "            ) as llm_span:\n",
    "                response = client.models.generate_content(\n",
    "                    model=MODEL,\n",
    "                    contents=prompt\n",
    "                )\n",
    "                result = response.text\n",
    "                \n",
    "                # Record token usage if available\n",
    "                if hasattr(response, 'usage_metadata'):\n",
    "                    llm_span.set_attribute(\"llm.usage.prompt_tokens\", \n",
    "                                          getattr(response.usage_metadata, 'prompt_token_count', 0))\n",
    "                    llm_span.set_attribute(\"llm.usage.completion_tokens\", \n",
    "                                          getattr(response.usage_metadata, 'candidates_token_count', 0))\n",
    "            \n",
    "            # Record output\n",
    "            span.set_attribute(\"traceloop.entity.output\", result[:500])\n",
    "            span.set_attribute(\"agent.status\", \"success\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            span.set_attribute(\"agent.status\", \"error\")\n",
    "            span.set_attribute(\"agent.error\", str(e))\n",
    "            span.record_exception(e)\n",
    "            raise\n",
    "\n",
    "print(\"‚úÖ Agent call function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define the MAS Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_research_mas(topic: str, max_refinements: int = 2) -> dict:\n",
    "    \"\"\"\n",
    "    Run the full MAS workflow:\n",
    "    1. Two researchers work in parallel\n",
    "    2. Writer synthesizes results\n",
    "    3. Critic reviews in a loop until approved\n",
    "    \"\"\"\n",
    "    tracer = trace.get_tracer(\"research-mas\")\n",
    "    \n",
    "    with tracer.start_as_current_span(\n",
    "        \"MAS.workflow\",\n",
    "        attributes={\n",
    "            \"traceloop.workflow.name\": \"research-workflow\",\n",
    "            \"workflow.topic\": topic,\n",
    "            \"workflow.max_refinements\": max_refinements\n",
    "        }\n",
    "    ) as workflow_span:\n",
    "        \n",
    "        results = {\"topic\": topic, \"iterations\": []}\n",
    "        \n",
    "        # ========== PHASE 1: Parallel Research ==========\n",
    "        print(\"\\nüìö Phase 1: Parallel Research\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"phase.parallel_research\",\n",
    "            attributes={\"phase\": \"research\", \"parallel\": True}\n",
    "        ):\n",
    "            research_task = f\"Research the topic: {topic}\"\n",
    "            \n",
    "            # Run researchers in parallel\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "                tech_future = executor.submit(\n",
    "                    call_agent, \"technical_researcher\", \n",
    "                    research_task + \" Focus on technical aspects.\"\n",
    "                )\n",
    "                biz_future = executor.submit(\n",
    "                    call_agent, \"business_researcher\", \n",
    "                    research_task + \" Focus on business aspects.\"\n",
    "                )\n",
    "                \n",
    "                tech_research = tech_future.result()\n",
    "                biz_research = biz_future.result()\n",
    "            \n",
    "            print(\"  ‚úÖ Technical Researcher: done\")\n",
    "            print(\"  ‚úÖ Business Researcher: done\")\n",
    "            \n",
    "            results[\"technical_research\"] = tech_research\n",
    "            results[\"business_research\"] = biz_research\n",
    "        \n",
    "        # ========== PHASE 2: Sequential Writing ==========\n",
    "        print(\"\\n‚úçÔ∏è Phase 2: Writing\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"phase.writing\",\n",
    "            attributes={\"phase\": \"writing\", \"sequential\": True}\n",
    "        ):\n",
    "            combined_research = f\"\"\"Technical Research:\n",
    "{tech_research}\n",
    "\n",
    "Business Research:\n",
    "{biz_research}\"\"\"\n",
    "            \n",
    "            draft = call_agent(\n",
    "                \"writer\",\n",
    "                f\"Write a comprehensive article about: {topic}\",\n",
    "                context=combined_research\n",
    "            )\n",
    "            print(\"  ‚úÖ Writer: draft created\")\n",
    "            results[\"initial_draft\"] = draft\n",
    "        \n",
    "        # ========== PHASE 3: Critic Refinement Loop ==========\n",
    "        print(\"\\nüîÑ Phase 3: Critic Refinement Loop\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"phase.refinement_loop\",\n",
    "            attributes={\"phase\": \"refinement\", \"loop\": True}\n",
    "        ):\n",
    "            current_draft = draft\n",
    "            iteration = 0\n",
    "            approved = False\n",
    "            \n",
    "            while iteration < max_refinements and not approved:\n",
    "                iteration += 1\n",
    "                print(f\"  üîÑ Iteration {iteration}\")\n",
    "                \n",
    "                with tracer.start_as_current_span(\n",
    "                    f\"refinement.iteration_{iteration}\",\n",
    "                    attributes={\"iteration\": iteration}\n",
    "                ):\n",
    "                    # Critic reviews\n",
    "                    critique = call_agent(\n",
    "                        \"critic\",\n",
    "                        \"Review this document and provide feedback. Say 'APPROVED' if it's good.\",\n",
    "                        context=current_draft\n",
    "                    )\n",
    "                    \n",
    "                    results[\"iterations\"].append({\n",
    "                        \"iteration\": iteration,\n",
    "                        \"critique\": critique\n",
    "                    })\n",
    "                    \n",
    "                    if \"APPROVED\" in critique.upper():\n",
    "                        approved = True\n",
    "                        print(f\"  ‚úÖ Critic: APPROVED\")\n",
    "                    else:\n",
    "                        print(f\"  üìù Critic: Requested changes\")\n",
    "                        # Writer revises based on feedback\n",
    "                        current_draft = call_agent(\n",
    "                            \"writer\",\n",
    "                            f\"Revise the document based on this feedback:\\n{critique}\",\n",
    "                            context=current_draft\n",
    "                        )\n",
    "                        results[\"iterations\"][-1][\"revised_draft\"] = current_draft\n",
    "            \n",
    "            results[\"final_draft\"] = current_draft\n",
    "            results[\"approved\"] = approved\n",
    "            results[\"total_iterations\"] = iteration\n",
    "        \n",
    "        workflow_span.set_attribute(\"workflow.approved\", approved)\n",
    "        workflow_span.set_attribute(\"workflow.iterations\", iteration)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Workflow complete! Approved: {approved}, Iterations: {iteration}\")\n",
    "        return results\n",
    "\n",
    "print(\"‚úÖ MAS workflow defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run the MAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the MAS with a sample topic\n",
    "TOPIC = \"The impact of Large Language Models on software development productivity\"\n",
    "\n",
    "print(f\"üöÄ Starting MAS workflow for topic:\\n'{TOPIC}'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = run_research_mas(TOPIC, max_refinements=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÑ Final Output Preview:\")\n",
    "print(\"=\"*60)\n",
    "print(results[\"final_draft\"][:1000] + \"...\" if len(results[\"final_draft\"]) > 1000 else results[\"final_draft\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save OTel Traces to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop tracing and save to JSON\n",
    "trace_file = capture.stop_and_save()\n",
    "\n",
    "print(f\"\\nüìÅ Traces saved to: {trace_file}\")\n",
    "print(f\"üìä Total spans captured: {len(capture.get_serialized_spans())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the raw OTel traces JSON\n",
    "import json\n",
    "\n",
    "with open(\"mas_traces.json\", \"r\") as f:\n",
    "    raw_traces = json.load(f)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìã RAW OPENTELEMETRY TRACES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Metadata: {raw_traces['capture_metadata']}\")\n",
    "print(f\"\\nFirst 3 spans:\")\n",
    "for span in raw_traces['spans'][:3]:\n",
    "    print(f\"  - {span['name']} ({span['duration_ms']:.0f}ms)\")\n",
    "    print(f\"    Attributes: {list(span['attributes'].keys())[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Convert to Agentic Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw traces to agentic analytics format\n",
    "analytics = convert_otel_to_analytics(\"mas_traces.json\", \"mas_analytics.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä AGENTIC ANALYTICS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Session ID: {analytics['session_id'][:16]}...\")\n",
    "print(f\"Total Duration: {analytics['total_duration_ms']:.0f}ms\")\n",
    "print(f\"\\nSummary:\")\n",
    "for key, value in analytics['summary'].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View agents extracted\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ü§ñ AGENTS DETECTED\")\n",
    "print(\"=\" * 60)\n",
    "for agent in analytics['agents']:\n",
    "    print(f\"\\n  Agent: {agent['name']}\")\n",
    "    if agent.get('role'):\n",
    "        print(f\"    Role: {agent['role']}\")\n",
    "    if agent.get('goal'):\n",
    "        print(f\"    Goal: {agent['goal'][:50]}...\" if len(agent.get('goal', '')) > 50 else f\"    Goal: {agent.get('goal')}\")\n",
    "    print(f\"    LLM Calls: {agent['llm_calls']}\")\n",
    "    print(f\"    Token Usage: {agent['token_usage']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View task flow (hierarchical)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã TASK FLOW (First 10 tasks)\")\n",
    "print(\"=\" * 60)\n",
    "for task in analytics['task_flow'][:10]:\n",
    "    indent = \"  \" if task['parent_id'] else \"\"\n",
    "    status_emoji = \"‚úÖ\" if task['status'] == \"OK\" else \"‚ö†Ô∏è\"\n",
    "    print(f\"{indent}{status_emoji} {task['name']} [{task['span_type']}] - {task['duration_ms']:.0f}ms\")\n",
    "    if task.get('agent'):\n",
    "        print(f\"{indent}   Agent: {task['agent']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View flow graph structure\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîó FLOW GRAPH\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nodes: {len(analytics['flow_graph']['nodes'])}\")\n",
    "print(f\"Edges: {len(analytics['flow_graph']['edges'])}\")\n",
    "\n",
    "print(\"\\nSample edges:\")\n",
    "for edge in analytics['flow_graph']['edges'][:5]:\n",
    "    print(f\"  {edge['source'][:8]}... --[{edge['edge_type']}]--> {edge['target'][:8]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Download the JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download both JSON files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Downloading JSON files...\")\n",
    "files.download(\"mas_traces.json\")\n",
    "files.download(\"mas_analytics.json\")\n",
    "print(\"‚úÖ Download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Full JSON Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full analytics JSON\n",
    "print(json.dumps(analytics, indent=2)[:5000])\n",
    "print(\"\\n... (truncated for display)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
